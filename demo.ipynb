{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Poutyne tutorial\n",
    "\n",
    "This notebook demonstrate how to use poutyne on a simple dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Autoreload is to always reload the imported python files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Matplotlib inline allows to make plot inline with the notebook with Matplotlib\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import all packages\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from poutyne import Model, SKLearnMetrics\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "from utils import metric_flatten, get_poutyne_callbacks, saferm\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# These line allows to select the first GPU of the machine or the CPU is not GPU is present\n",
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Generation of a simple dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def func(xx,yy):\n",
    "    y = 2*np.sin(10*((xx-0.7)) + 5* (yy-0.3)**2)\n",
    "    return y\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = np.arange(0, 1, 0.02)\n",
    "y = np.arange(0, 1, 0.02)\n",
    "xx, yy = np.meshgrid(x, y, sparse=False)\n",
    "z = func(xx,yy)\n",
    "h = plt.contourf(x, y, z)\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## dataset creation\n",
    "def sample_generator_regression(n):\n",
    "    # RRandom sampling of points\n",
    "    x = np.random.rand(n, 2).astype(np.float32)\n",
    "    # compute the output\n",
    "    # we expand the dimension to have the size [n x 1], which will be the output shape of the NN.\n",
    "    y = np.expand_dims(func(x[:,0], x[:,1]),axis=1)\n",
    "    # Convertion to Pytorch tensors\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "train_data = sample_generator_regression(1024)\n",
    "valid_data = sample_generator_regression(64)\n",
    "test_data = sample_generator_regression(128)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# It is very practical to transform our data into torch dataset\n",
    "train_dataset = TensorDataset(*train_data)\n",
    "valid_dataset = TensorDataset(*valid_data)\n",
    "test_dataset = TensorDataset(*test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Definition of the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Definition of a NN with 4 Linear layers\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, input_size = 2, output_size = 1, n_hidden=64):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear4 = nn.Linear(n_hidden, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.leaky_relu(self.linear1(x))\n",
    "        x2 = F.leaky_relu(self.linear2(x1))\n",
    "        x3 = F.leaky_relu(self.linear3(x2))\n",
    "        x4 = self.linear4(x3)\n",
    "        return x4\n",
    "\n",
    "network = LinearNet(input_size = 2, output_size = 1, n_hidden=64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The package `torchsummary` allows to display a summary of the model\n",
    "summary(network, (2,))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define a poutyne model with optimizer, loss and metrics\n",
    "model = Model(network, 'adam', 'mse',\n",
    "              batch_metrics=[\"l1\"],\n",
    "              epoch_metrics=[ SKLearnMetrics(metric_flatten(r2_score)), \n",
    "                              SKLearnMetrics(metric_flatten(median_absolute_error))\n",
    "                            ],\n",
    "              device=device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment_name = \"test\"\n",
    "callbacks, summary_dir, checkpoint_dir = get_poutyne_callbacks(experiment_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# optimization paramters\n",
    "optimization_kwargs = {}\n",
    "optimization_kwargs[\"batch_size\"] = 8\n",
    "optimization_kwargs[\"epochs\"] = 15\n",
    "\n",
    "# # delete the folder for summaries and checkpoints\n",
    "# saferm(summary_dir)\n",
    "# saferm(checkpoint_dir)\n",
    "# summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "# checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# train the model\n",
    "# note that the function will load the model with best validation score at the end\n",
    "history = model.fit_dataset(train_dataset, valid_dataset=valid_dataset, **optimization_kwargs, callbacks=callbacks) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluate the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function `fit` returns a list of information for each epoch. We can simply plot convergence curves using it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e = [int(v['epoch']) for v in history]\n",
    "val_loss = [v['val_loss'] for v in history]\n",
    "train_loss = [v['loss'] for v in history]\n",
    "plt.plot(e, train_loss, \"-x\" ,label=\"Training\")\n",
    "plt.plot(e, val_loss,\"-x\", label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"MSE\")\n",
    "plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compute the score on the test set.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate_dataset(test_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also perform prediction on a grid of points an look at the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = np.arange(0, 1, 0.02)\n",
    "y = np.arange(0, 1, 0.02)\n",
    "xx, yy = np.meshgrid(x, y, sparse=False)\n",
    "Z1 = func(xx,yy)\n",
    "\n",
    "X = torch.tensor(np.array([xx.reshape(-1), yy.reshape(-1)]).T.astype(np.float32))\n",
    "Z2 = model.predict(X).reshape(xx.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vmin = np.min(Z1)\n",
    "vmax = np.max(Z1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1)\n",
    "# h = plt.contourf(x, y, Z1, vmin=vmin, vmax=vmax)\n",
    "plt.imshow(Z1, vmin=vmin, vmax=vmax, extent=[0,1,0,1])\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')\n",
    "plt.title(\"Ground truth\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Z2, vmin=vmin, vmax=vmax, extent=[0,1,0,1])\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')\n",
    "plt.title(\"Neural network\");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d6757ca33321953b12ceb7dd04072680bb2c30568fe835386031ea5afad42c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('summerschool-1rr7yiI2': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}